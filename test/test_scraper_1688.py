#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
1688å•†å“æŠ“å–åŠŸèƒ½æµ‹è¯•
æµ‹è¯•scraper_1688æ¨¡å—çš„å„é¡¹åŠŸèƒ½
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import unittest
from scraper_1688 import scrape_1688_product
import json
import time

class Test1688Scraper(unittest.TestCase):
    """1688æŠ“å–å™¨æµ‹è¯•ç±»"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_urls = [
            "https://detail.1688.com/offer/793064484013.html",
            "https://detail.1688.com/offer/825677770251.html",
            "https://detail.1688.com/offer/800015139408.html"
        ]
        
    def test_basic_scraping(self):
        """æµ‹è¯•åŸºæœ¬æŠ“å–åŠŸèƒ½"""
        print("\n=== æµ‹è¯•åŸºæœ¬æŠ“å–åŠŸèƒ½ ===")
        
        for i, url in enumerate(self.test_urls, 1):
            print(f"\n{i}. æµ‹è¯•URL: {url}")
            
            try:
                result = scrape_1688_product(url)
                
                # æ£€æŸ¥ç»“æœæ˜¯å¦åŒ…å«é”™è¯¯
                self.assertNotIn('error', result, f"æŠ“å–URL {url} æ—¶å‡ºç°é”™è¯¯: {result.get('error', '')}")
                
                # æ£€æŸ¥å¿…éœ€å­—æ®µ
                required_fields = ['title', 'price', 'url', 'product_id']
                for field in required_fields:
                    self.assertIn(field, result, f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                    self.assertIsNotNone(result[field], f"å­—æ®µ {field} ä¸ºNone")
                    self.assertNotEqual(result[field], 'N/A', f"å­—æ®µ {field} ä¸ºN/A")
                
                # æ‰“å°æŠ“å–ç»“æœæ‘˜è¦
                print(f"   âœ… æ ‡é¢˜: {result.get('title', 'N/A')[:50]}...")
                print(f"   âœ… ä»·æ ¼: {result.get('price', 'N/A')}")
                print(f"   âœ… å›¾ç‰‡æ•°é‡: {len(result.get('images', []))}")
                print(f"   âœ… è§„æ ¼å‚æ•°æ•°é‡: {len(result.get('specifications', {}))}")
                print(f"   âœ… æè¿°é•¿åº¦: {len(result.get('description', ''))}")
                
                # éªŒè¯æŠ“å–è´¨é‡
                self.assertGreater(len(result.get('title', '')), 5, "æ ‡é¢˜å¤ªçŸ­")
                self.assertGreater(len(result.get('images', [])), 0, "æ²¡æœ‰æŠ“å–åˆ°å›¾ç‰‡")
                
            except Exception as e:
                self.fail(f"æŠ“å–URL {url} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                
            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(2)
    
    def test_image_extraction(self):
        """æµ‹è¯•å›¾ç‰‡æå–åŠŸèƒ½"""
        print("\n=== æµ‹è¯•å›¾ç‰‡æå–åŠŸèƒ½ ===")
        
        url = self.test_urls[0]
        result = scrape_1688_product(url)
        
        images = result.get('images', [])
        self.assertGreater(len(images), 0, "æ²¡æœ‰æå–åˆ°ä»»ä½•å›¾ç‰‡")
        
        # æ£€æŸ¥å›¾ç‰‡URLæ ¼å¼
        for i, img_url in enumerate(images[:3]):  # åªæ£€æŸ¥å‰3å¼ 
            self.assertTrue(img_url.startswith('http'), f"å›¾ç‰‡{i+1}çš„URLæ ¼å¼ä¸æ­£ç¡®: {img_url}")
            print(f"   âœ… å›¾ç‰‡{i+1}: {img_url}")
    
    def test_specifications_extraction(self):
        """æµ‹è¯•è§„æ ¼å‚æ•°æå–åŠŸèƒ½"""
        print("\n=== æµ‹è¯•è§„æ ¼å‚æ•°æå–åŠŸèƒ½ ===")
        
        url = self.test_urls[0]
        result = scrape_1688_product(url)
        
        specifications = result.get('specifications', {})
        print(f"   æå–åˆ° {len(specifications)} ä¸ªè§„æ ¼å‚æ•°")
        
        if specifications:
            # æ‰“å°å‰5ä¸ªè§„æ ¼å‚æ•°
            for i, (key, value) in enumerate(list(specifications.items())[:5]):
                print(f"   âœ… {key}: {value}")
                self.assertIsInstance(key, str, "è§„æ ¼å‚æ•°ååº”è¯¥æ˜¯å­—ç¬¦ä¸²")
                self.assertIsInstance(value, str, "è§„æ ¼å‚æ•°å€¼åº”è¯¥æ˜¯å­—ç¬¦ä¸²")
        else:
            print("   âš ï¸ æœªæå–åˆ°è§„æ ¼å‚æ•°")
    
    def test_mobile_fallback(self):
        """æµ‹è¯•ç§»åŠ¨ç‰ˆé™çº§åŠŸèƒ½"""
        print("\n=== æµ‹è¯•ç§»åŠ¨ç‰ˆé™çº§åŠŸèƒ½ ===")
        
        # ä½¿ç”¨ä¸€ä¸ªå¯èƒ½åœ¨æ¡Œé¢ç‰ˆæŠ“å–å›°éš¾çš„URL
        url = self.test_urls[1]
        result = scrape_1688_product(url)
        
        self.assertNotIn('error', result, f"ç§»åŠ¨ç‰ˆé™çº§å¤±è´¥: {result.get('error', '')}")
        print(f"   âœ… ç§»åŠ¨ç‰ˆé™çº§æˆåŠŸ")
        print(f"   âœ… æ ‡é¢˜: {result.get('title', 'N/A')[:50]}...")
    
    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        print("\n=== æµ‹è¯•é”™è¯¯å¤„ç† ===")
        
        invalid_urls = [
            "https://invalid-url.com",
            "https://detail.1688.com/offer/invalid.html",
            "not-a-url"
        ]
        
        for url in invalid_urls:
            print(f"   æµ‹è¯•æ— æ•ˆURL: {url}")
            result = scrape_1688_product(url)
            
            # æ— æ•ˆURLåº”è¯¥è¿”å›é”™è¯¯ä¿¡æ¯
            if 'error' in result:
                print(f"   âœ… æ­£ç¡®å¤„ç†äº†æ— æ•ˆURL: {result['error']}")
            else:
                print(f"   âš ï¸ æ— æ•ˆURLæœªè¿”å›é”™è¯¯ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥")

def run_scraper_tests():
    """è¿è¡ŒæŠ“å–å™¨æµ‹è¯•"""
    print("ğŸ” å¼€å§‹1688æŠ“å–åŠŸèƒ½æµ‹è¯•...")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    suite = unittest.TestLoader().loadTestsFromTestCase(Test1688Scraper)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦:")
    print(f"   æ€»æµ‹è¯•æ•°: {result.testsRun}")
    print(f"   æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"   å¤±è´¥: {len(result.failures)}")
    print(f"   é”™è¯¯: {len(result.errors)}")
    
    if result.failures:
        print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"   - {test}: {traceback}")
    
    if result.errors:
        print("\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"   - {test}: {traceback}")
    
    if result.wasSuccessful():
        print("\nğŸ‰ æ‰€æœ‰æŠ“å–åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
        return False

if __name__ == "__main__":
    run_scraper_tests()